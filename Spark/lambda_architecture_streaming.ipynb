{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07d37af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "691fb65f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "22/03/10 16:47:13 WARN util.Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "22/03/10 16:47:13 WARN util.Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n"
     ]
    }
   ],
   "source": [
    "# %fs   - for using in DataBricks, \"spark\" already runned\n",
    "# ls /databricks-datasets\n",
    "\n",
    "spark = SparkSession.builder\\\n",
    "    .master(\"local\")\\\n",
    "    .appName(\"lambda\")\\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0626e315",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "orders_df = spark.read\\\n",
    "   .option(\"header\", True)\\\n",
    "   .option(\"inferSchema\", True)\\\n",
    "   .csv(\"/datalake/bronze/dshop/orders/spark_stream/orders_2022-02-24.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "79bf8be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "orders_schema = [i for i in orders_df.schema]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b719dad2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[StructField(order_id,IntegerType,true),\n",
       " StructField(product_id,IntegerType,true),\n",
       " StructField(client_id,IntegerType,true),\n",
       " StructField(store_id,IntegerType,true),\n",
       " StructField(quantity,IntegerType,true),\n",
       " StructField(order_date,StringType,true)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orders_schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "33d22237",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_schema = StructType(orders_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c0998f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "orders_data = spark.readStream\\\n",
    "    .schema(csv_schema)\\\n",
    "    .option(\"maxFilesPerTrigger\", 1)\\\n",
    "    .csv(\"/datalake/bronze/dshop/orders/spark_stream/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2078e2d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/03/10 16:49:13 WARN streaming.StreamingQueryManager: Temporary checkpoint location created which is deleted normally when the query didn't fail: /tmp/temporary-c06af648-1bc2-4100-b8e4-6c610a025fdc. If it's required to delete it under any circumstances, please set spark.sql.streaming.forceDeleteTempCheckpointLocation to true. Important to know deleting temp checkpoint folder is best effort.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pyspark.sql.streaming.StreamingQuery at 0x7fc25404c0d0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/03/10 16:50:08 ERROR executor.Executor: Exception in task 0.0 in stage 8.0 (TID 8)\n",
      "java.lang.OutOfMemoryError: Java heap space\n",
      "\tat java.util.Arrays.copyOf(Arrays.java:3236)\n",
      "\tat java.io.ByteArrayOutputStream.grow(ByteArrayOutputStream.java:118)\n",
      "\tat java.io.ByteArrayOutputStream.ensureCapacity(ByteArrayOutputStream.java:93)\n",
      "\tat java.io.ByteArrayOutputStream.write(ByteArrayOutputStream.java:153)\n",
      "\tat org.apache.spark.util.ByteBufferOutputStream.write(ByteBufferOutputStream.scala:41)\n",
      "\tat java.io.ObjectOutputStream$BlockDataOutputStream.write(ObjectOutputStream.java:1853)\n",
      "\tat java.io.ObjectOutputStream.write(ObjectOutputStream.java:709)\n",
      "\tat org.apache.spark.util.Utils$.writeByteBuffer(Utils.scala:233)\n",
      "\tat org.apache.spark.scheduler.DirectTaskResult.$anonfun$writeExternal$1(TaskResult.scala:53)\n",
      "\tat org.apache.spark.scheduler.DirectTaskResult$$Lambda$2262/241322712.apply$mcV$sp(Unknown Source)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.tryOrIOException(Utils.scala:1405)\n",
      "\tat org.apache.spark.scheduler.DirectTaskResult.writeExternal(TaskResult.scala:51)\n",
      "\tat java.io.ObjectOutputStream.writeExternalData(ObjectOutputStream.java:1459)\n",
      "\tat java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1430)\n",
      "\tat java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1178)\n",
      "\tat java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:348)\n",
      "\tat org.apache.spark.serializer.JavaSerializationStream.writeObject(JavaSerializer.scala:44)\n",
      "\tat org.apache.spark.serializer.JavaSerializerInstance.serialize(JavaSerializer.scala:101)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:606)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/03/10 16:50:08 ERROR util.SparkUncaughtExceptionHandler: Uncaught exception in thread Thread[Executor task launch worker for task 0.0 in stage 8.0 (TID 8),5,main]\n",
      "java.lang.OutOfMemoryError: Java heap space\n",
      "\tat java.util.Arrays.copyOf(Arrays.java:3236)\n",
      "\tat java.io.ByteArrayOutputStream.grow(ByteArrayOutputStream.java:118)\n",
      "\tat java.io.ByteArrayOutputStream.ensureCapacity(ByteArrayOutputStream.java:93)\n",
      "\tat java.io.ByteArrayOutputStream.write(ByteArrayOutputStream.java:153)\n",
      "\tat org.apache.spark.util.ByteBufferOutputStream.write(ByteBufferOutputStream.scala:41)\n",
      "\tat java.io.ObjectOutputStream$BlockDataOutputStream.write(ObjectOutputStream.java:1853)\n",
      "\tat java.io.ObjectOutputStream.write(ObjectOutputStream.java:709)\n",
      "\tat org.apache.spark.util.Utils$.writeByteBuffer(Utils.scala:233)\n",
      "\tat org.apache.spark.scheduler.DirectTaskResult.$anonfun$writeExternal$1(TaskResult.scala:53)\n",
      "\tat org.apache.spark.scheduler.DirectTaskResult$$Lambda$2262/241322712.apply$mcV$sp(Unknown Source)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.tryOrIOException(Utils.scala:1405)\n",
      "\tat org.apache.spark.scheduler.DirectTaskResult.writeExternal(TaskResult.scala:51)\n",
      "\tat java.io.ObjectOutputStream.writeExternalData(ObjectOutputStream.java:1459)\n",
      "\tat java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1430)\n",
      "\tat java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1178)\n",
      "\tat java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:348)\n",
      "\tat org.apache.spark.serializer.JavaSerializationStream.writeObject(JavaSerializer.scala:44)\n",
      "\tat org.apache.spark.serializer.JavaSerializerInstance.serialize(JavaSerializer.scala:101)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:606)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/03/10 16:50:08 WARN scheduler.TaskSetManager: Lost task 0.0 in stage 8.0 (TID 8) (0.0.0.0 executor driver): java.lang.OutOfMemoryError: Java heap space\n",
      "\tat java.util.Arrays.copyOf(Arrays.java:3236)\n",
      "\tat java.io.ByteArrayOutputStream.grow(ByteArrayOutputStream.java:118)\n",
      "\tat java.io.ByteArrayOutputStream.ensureCapacity(ByteArrayOutputStream.java:93)\n",
      "\tat java.io.ByteArrayOutputStream.write(ByteArrayOutputStream.java:153)\n",
      "\tat org.apache.spark.util.ByteBufferOutputStream.write(ByteBufferOutputStream.scala:41)\n",
      "\tat java.io.ObjectOutputStream$BlockDataOutputStream.write(ObjectOutputStream.java:1853)\n",
      "\tat java.io.ObjectOutputStream.write(ObjectOutputStream.java:709)\n",
      "\tat org.apache.spark.util.Utils$.writeByteBuffer(Utils.scala:233)\n",
      "\tat org.apache.spark.scheduler.DirectTaskResult.$anonfun$writeExternal$1(TaskResult.scala:53)\n",
      "\tat org.apache.spark.scheduler.DirectTaskResult$$Lambda$2262/241322712.apply$mcV$sp(Unknown Source)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.tryOrIOException(Utils.scala:1405)\n",
      "\tat org.apache.spark.scheduler.DirectTaskResult.writeExternal(TaskResult.scala:51)\n",
      "\tat java.io.ObjectOutputStream.writeExternalData(ObjectOutputStream.java:1459)\n",
      "\tat java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1430)\n",
      "\tat java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1178)\n",
      "\tat java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:348)\n",
      "\tat org.apache.spark.serializer.JavaSerializationStream.writeObject(JavaSerializer.scala:44)\n",
      "\tat org.apache.spark.serializer.JavaSerializerInstance.serialize(JavaSerializer.scala:101)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:606)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/03/10 16:50:08 ERROR scheduler.TaskSetManager: Task 0 in stage 8.0 failed 1 times; aborting job\n",
      "22/03/10 16:50:08 ERROR v2.WriteToDataSourceV2Exec: Data source write support org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@5398d82c is aborting.\n",
      "22/03/10 16:50:08 ERROR v2.WriteToDataSourceV2Exec: Data source write support org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@5398d82c aborted.\n",
      "22/03/10 16:50:08 ERROR streaming.MicroBatchExecution: Query orders_stream [id = 4f1d888b-e18c-4857-b5fa-0ab5ff1d9cb9, runId = 76e62d87-e6b8-410f-9c5b-a3bb4855cbd7] terminated with error\n",
      "org.apache.spark.SparkException: Writing job aborted.\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2TableWriteExec.writeWithV2(WriteToDataSourceV2Exec.scala:388)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2TableWriteExec.writeWithV2$(WriteToDataSourceV2Exec.scala:336)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.WriteToDataSourceV2Exec.writeWithV2(WriteToDataSourceV2Exec.scala:297)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.WriteToDataSourceV2Exec.run(WriteToDataSourceV2Exec.scala:304)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.collectFromPlan(Dataset.scala:3696)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$collect$1(Dataset.scala:2965)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:772)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.collect(Dataset.scala:2965)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$16(MicroBatchExecution.scala:589)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:772)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$15(MicroBatchExecution.scala:584)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:357)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:355)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:68)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runBatch(MicroBatchExecution.scala:584)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:226)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:357)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:355)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:68)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:194)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:57)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:188)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:333)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:244)\n",
      "Caused by: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 8.0 failed 1 times, most recent failure: Lost task 0.0 in stage 8.0 (TID 8) (0.0.0.0 executor driver): java.lang.OutOfMemoryError: Java heap space\n",
      "\tat java.util.Arrays.copyOf(Arrays.java:3236)\n",
      "\tat java.io.ByteArrayOutputStream.grow(ByteArrayOutputStream.java:118)\n",
      "\tat java.io.ByteArrayOutputStream.ensureCapacity(ByteArrayOutputStream.java:93)\n",
      "\tat java.io.ByteArrayOutputStream.write(ByteArrayOutputStream.java:153)\n",
      "\tat org.apache.spark.util.ByteBufferOutputStream.write(ByteBufferOutputStream.scala:41)\n",
      "\tat java.io.ObjectOutputStream$BlockDataOutputStream.write(ObjectOutputStream.java:1853)\n",
      "\tat java.io.ObjectOutputStream.write(ObjectOutputStream.java:709)\n",
      "\tat org.apache.spark.util.Utils$.writeByteBuffer(Utils.scala:233)\n",
      "\tat org.apache.spark.scheduler.DirectTaskResult.$anonfun$writeExternal$1(TaskResult.scala:53)\n",
      "\tat org.apache.spark.scheduler.DirectTaskResult$$Lambda$2262/241322712.apply$mcV$sp(Unknown Source)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.tryOrIOException(Utils.scala:1405)\n",
      "\tat org.apache.spark.scheduler.DirectTaskResult.writeExternal(TaskResult.scala:51)\n",
      "\tat java.io.ObjectOutputStream.writeExternalData(ObjectOutputStream.java:1459)\n",
      "\tat java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1430)\n",
      "\tat java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1178)\n",
      "\tat java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:348)\n",
      "\tat org.apache.spark.serializer.JavaSerializationStream.writeObject(JavaSerializer.scala:44)\n",
      "\tat org.apache.spark.serializer.JavaSerializerInstance.serialize(JavaSerializer.scala:101)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:606)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2253)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2202)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2201)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2201)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1078)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1078)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1078)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2440)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2382)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2371)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:868)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2202)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2TableWriteExec.writeWithV2(WriteToDataSourceV2Exec.scala:357)\n",
      "\t... 37 more\n",
      "Caused by: java.lang.OutOfMemoryError: Java heap space\n",
      "\tat java.util.Arrays.copyOf(Arrays.java:3236)\n",
      "\tat java.io.ByteArrayOutputStream.grow(ByteArrayOutputStream.java:118)\n",
      "\tat java.io.ByteArrayOutputStream.ensureCapacity(ByteArrayOutputStream.java:93)\n",
      "\tat java.io.ByteArrayOutputStream.write(ByteArrayOutputStream.java:153)\n",
      "\tat org.apache.spark.util.ByteBufferOutputStream.write(ByteBufferOutputStream.scala:41)\n",
      "\tat java.io.ObjectOutputStream$BlockDataOutputStream.write(ObjectOutputStream.java:1853)\n",
      "\tat java.io.ObjectOutputStream.write(ObjectOutputStream.java:709)\n",
      "\tat org.apache.spark.util.Utils$.writeByteBuffer(Utils.scala:233)\n",
      "\tat org.apache.spark.scheduler.DirectTaskResult.$anonfun$writeExternal$1(TaskResult.scala:53)\n",
      "\tat org.apache.spark.scheduler.DirectTaskResult$$Lambda$2262/241322712.apply$mcV$sp(Unknown Source)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.tryOrIOException(Utils.scala:1405)\n",
      "\tat org.apache.spark.scheduler.DirectTaskResult.writeExternal(TaskResult.scala:51)\n",
      "\tat java.io.ObjectOutputStream.writeExternalData(ObjectOutputStream.java:1459)\n",
      "\tat java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1430)\n",
      "\tat java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1178)\n",
      "\tat java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:348)\n",
      "\tat org.apache.spark.serializer.JavaSerializationStream.writeObject(JavaSerializer.scala:44)\n",
      "\tat org.apache.spark.serializer.JavaSerializerInstance.serialize(JavaSerializer.scala:101)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:606)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n"
     ]
    }
   ],
   "source": [
    "orders_data.writeStream\\\n",
    "    .format('memory')\\\n",
    "    .queryName('orders_stream')\\\n",
    "    .outputMode(\"append\")\\\n",
    "    .start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "80cbee00",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Exception while sending command.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user/.local/lib/python3.8/site-packages/py4j/java_gateway.py\", line 1207, in send_command\n",
      "    raise Py4JNetworkError(\"Answer from Java side is empty\")\n",
      "py4j.protocol.Py4JNetworkError: Answer from Java side is empty\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user/.local/lib/python3.8/site-packages/py4j/java_gateway.py\", line 1033, in send_command\n",
      "    response = connection.send_command(command)\n",
      "  File \"/home/user/.local/lib/python3.8/site-packages/py4j/java_gateway.py\", line 1211, in send_command\n",
      "    raise Py4JNetworkError(\n",
      "py4j.protocol.Py4JNetworkError: Error while receiving\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:40965)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3251, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_24253/2671758561.py\", line 1, in <module>\n",
      "    orders_stream_df = spark.table(\"orders_stream\").where(col('store_id') == 1)\n",
      "  File \"/home/user/.local/lib/python3.8/site-packages/pyspark/sql/session.py\", line 741, in table\n",
      "    return DataFrame(self._jsparkSession.table(tableName), self._wrapped)\n",
      "  File \"/home/user/.local/lib/python3.8/site-packages/py4j/java_gateway.py\", line 1304, in __call__\n",
      "    return_value = get_return_value(\n",
      "  File \"/home/user/.local/lib/python3.8/site-packages/pyspark/sql/utils.py\", line 111, in deco\n",
      "    return f(*a, **kw)\n",
      "  File \"/home/user/.local/lib/python3.8/site-packages/py4j/protocol.py\", line 334, in get_return_value\n",
      "    raise Py4JError(\n",
      "py4j.protocol.Py4JError: An error occurred while calling o23.table\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 1934, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'Py4JError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user/.local/lib/python3.8/site-packages/py4j/java_gateway.py\", line 977, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user/.local/lib/python3.8/site-packages/py4j/java_gateway.py\", line 1115, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:40965)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3251, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_24253/2671758561.py\", line 1, in <module>\n",
      "    orders_stream_df = spark.table(\"orders_stream\").where(col('store_id') == 1)\n",
      "  File \"/home/user/.local/lib/python3.8/site-packages/pyspark/sql/session.py\", line 741, in table\n",
      "    return DataFrame(self._jsparkSession.table(tableName), self._wrapped)\n",
      "  File \"/home/user/.local/lib/python3.8/site-packages/py4j/java_gateway.py\", line 1304, in __call__\n",
      "    return_value = get_return_value(\n",
      "  File \"/home/user/.local/lib/python3.8/site-packages/pyspark/sql/utils.py\", line 111, in deco\n",
      "    return f(*a, **kw)\n",
      "  File \"/home/user/.local/lib/python3.8/site-packages/py4j/protocol.py\", line 334, in get_return_value\n",
      "    raise Py4JError(\n",
      "py4j.protocol.Py4JError: An error occurred while calling o23.table\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 1934, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'Py4JError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user/.local/lib/python3.8/site-packages/py4j/java_gateway.py\", line 977, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user/.local/lib/python3.8/site-packages/py4j/java_gateway.py\", line 1115, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:40965)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3251, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_24253/2671758561.py\", line 1, in <module>\n",
      "    orders_stream_df = spark.table(\"orders_stream\").where(col('store_id') == 1)\n",
      "  File \"/home/user/.local/lib/python3.8/site-packages/pyspark/sql/session.py\", line 741, in table\n",
      "    return DataFrame(self._jsparkSession.table(tableName), self._wrapped)\n",
      "  File \"/home/user/.local/lib/python3.8/site-packages/py4j/java_gateway.py\", line 1304, in __call__\n",
      "    return_value = get_return_value(\n",
      "  File \"/home/user/.local/lib/python3.8/site-packages/pyspark/sql/utils.py\", line 111, in deco\n",
      "    return f(*a, **kw)\n",
      "  File \"/home/user/.local/lib/python3.8/site-packages/py4j/protocol.py\", line 334, in get_return_value\n",
      "    raise Py4JError(\n",
      "py4j.protocol.Py4JError: An error occurred while calling o23.table\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 1934, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'Py4JError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user/.local/lib/python3.8/site-packages/py4j/java_gateway.py\", line 977, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user/.local/lib/python3.8/site-packages/py4j/java_gateway.py\", line 1115, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:40965)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3251, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_24253/2671758561.py\", line 1, in <module>\n",
      "    orders_stream_df = spark.table(\"orders_stream\").where(col('store_id') == 1)\n",
      "  File \"/home/user/.local/lib/python3.8/site-packages/pyspark/sql/session.py\", line 741, in table\n",
      "    return DataFrame(self._jsparkSession.table(tableName), self._wrapped)\n",
      "  File \"/home/user/.local/lib/python3.8/site-packages/py4j/java_gateway.py\", line 1304, in __call__\n",
      "    return_value = get_return_value(\n",
      "  File \"/home/user/.local/lib/python3.8/site-packages/pyspark/sql/utils.py\", line 111, in deco\n",
      "    return f(*a, **kw)\n",
      "  File \"/home/user/.local/lib/python3.8/site-packages/py4j/protocol.py\", line 334, in get_return_value\n",
      "    raise Py4JError(\n",
      "py4j.protocol.Py4JError: An error occurred while calling o23.table\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 1934, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'Py4JError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user/.local/lib/python3.8/site-packages/py4j/java_gateway.py\", line 977, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user/.local/lib/python3.8/site-packages/py4j/java_gateway.py\", line 1115, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:40965)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3251, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_24253/2671758561.py\", line 1, in <module>\n",
      "    orders_stream_df = spark.table(\"orders_stream\").where(col('store_id') == 1)\n",
      "  File \"/home/user/.local/lib/python3.8/site-packages/pyspark/sql/session.py\", line 741, in table\n",
      "    return DataFrame(self._jsparkSession.table(tableName), self._wrapped)\n",
      "  File \"/home/user/.local/lib/python3.8/site-packages/py4j/java_gateway.py\", line 1304, in __call__\n",
      "    return_value = get_return_value(\n",
      "  File \"/home/user/.local/lib/python3.8/site-packages/pyspark/sql/utils.py\", line 111, in deco\n",
      "    return f(*a, **kw)\n",
      "  File \"/home/user/.local/lib/python3.8/site-packages/py4j/protocol.py\", line 334, in get_return_value\n",
      "    raise Py4JError(\n",
      "py4j.protocol.Py4JError: An error occurred while calling o23.table\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 1934, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'Py4JError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user/.local/lib/python3.8/site-packages/py4j/java_gateway.py\", line 977, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user/.local/lib/python3.8/site-packages/py4j/java_gateway.py\", line 1115, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:40965)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3251, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_24253/2671758561.py\", line 1, in <module>\n",
      "    orders_stream_df = spark.table(\"orders_stream\").where(col('store_id') == 1)\n",
      "  File \"/home/user/.local/lib/python3.8/site-packages/pyspark/sql/session.py\", line 741, in table\n",
      "    return DataFrame(self._jsparkSession.table(tableName), self._wrapped)\n",
      "  File \"/home/user/.local/lib/python3.8/site-packages/py4j/java_gateway.py\", line 1304, in __call__\n",
      "    return_value = get_return_value(\n",
      "  File \"/home/user/.local/lib/python3.8/site-packages/pyspark/sql/utils.py\", line 111, in deco\n",
      "    return f(*a, **kw)\n",
      "  File \"/home/user/.local/lib/python3.8/site-packages/py4j/protocol.py\", line 334, in get_return_value\n",
      "    raise Py4JError(\n",
      "py4j.protocol.Py4JError: An error occurred while calling o23.table\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 1934, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'Py4JError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user/.local/lib/python3.8/site-packages/py4j/java_gateway.py\", line 977, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user/.local/lib/python3.8/site-packages/py4j/java_gateway.py\", line 1115, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:40965)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3251, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_24253/2671758561.py\", line 1, in <module>\n",
      "    orders_stream_df = spark.table(\"orders_stream\").where(col('store_id') == 1)\n",
      "  File \"/home/user/.local/lib/python3.8/site-packages/pyspark/sql/session.py\", line 741, in table\n",
      "    return DataFrame(self._jsparkSession.table(tableName), self._wrapped)\n",
      "  File \"/home/user/.local/lib/python3.8/site-packages/py4j/java_gateway.py\", line 1304, in __call__\n",
      "    return_value = get_return_value(\n",
      "  File \"/home/user/.local/lib/python3.8/site-packages/pyspark/sql/utils.py\", line 111, in deco\n",
      "    return f(*a, **kw)\n",
      "  File \"/home/user/.local/lib/python3.8/site-packages/py4j/protocol.py\", line 334, in get_return_value\n",
      "    raise Py4JError(\n",
      "py4j.protocol.Py4JError: An error occurred while calling o23.table\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 1934, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'Py4JError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user/.local/lib/python3.8/site-packages/py4j/java_gateway.py\", line 977, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user/.local/lib/python3.8/site-packages/py4j/java_gateway.py\", line 1115, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:40965)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3251, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_24253/2671758561.py\", line 1, in <module>\n",
      "    orders_stream_df = spark.table(\"orders_stream\").where(col('store_id') == 1)\n",
      "  File \"/home/user/.local/lib/python3.8/site-packages/pyspark/sql/session.py\", line 741, in table\n",
      "    return DataFrame(self._jsparkSession.table(tableName), self._wrapped)\n",
      "  File \"/home/user/.local/lib/python3.8/site-packages/py4j/java_gateway.py\", line 1304, in __call__\n",
      "    return_value = get_return_value(\n",
      "  File \"/home/user/.local/lib/python3.8/site-packages/pyspark/sql/utils.py\", line 111, in deco\n",
      "    return f(*a, **kw)\n",
      "  File \"/home/user/.local/lib/python3.8/site-packages/py4j/protocol.py\", line 334, in get_return_value\n",
      "    raise Py4JError(\n",
      "py4j.protocol.Py4JError: An error occurred while calling o23.table\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 1934, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'Py4JError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user/.local/lib/python3.8/site-packages/py4j/java_gateway.py\", line 977, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user/.local/lib/python3.8/site-packages/py4j/java_gateway.py\", line 1115, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:40965)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3251, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_24253/2671758561.py\", line 1, in <module>\n",
      "    orders_stream_df = spark.table(\"orders_stream\").where(col('store_id') == 1)\n",
      "  File \"/home/user/.local/lib/python3.8/site-packages/pyspark/sql/session.py\", line 741, in table\n",
      "    return DataFrame(self._jsparkSession.table(tableName), self._wrapped)\n",
      "  File \"/home/user/.local/lib/python3.8/site-packages/py4j/java_gateway.py\", line 1304, in __call__\n",
      "    return_value = get_return_value(\n",
      "  File \"/home/user/.local/lib/python3.8/site-packages/pyspark/sql/utils.py\", line 111, in deco\n",
      "    return f(*a, **kw)\n",
      "  File \"/home/user/.local/lib/python3.8/site-packages/py4j/protocol.py\", line 334, in get_return_value\n",
      "    raise Py4JError(\n",
      "py4j.protocol.Py4JError: An error occurred while calling o23.table\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 1934, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'Py4JError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user/.local/lib/python3.8/site-packages/py4j/java_gateway.py\", line 977, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user/.local/lib/python3.8/site-packages/py4j/java_gateway.py\", line 1115, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:40965)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3251, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_24253/2671758561.py\", line 1, in <module>\n",
      "    orders_stream_df = spark.table(\"orders_stream\").where(col('store_id') == 1)\n",
      "  File \"/home/user/.local/lib/python3.8/site-packages/pyspark/sql/session.py\", line 741, in table\n",
      "    return DataFrame(self._jsparkSession.table(tableName), self._wrapped)\n",
      "  File \"/home/user/.local/lib/python3.8/site-packages/py4j/java_gateway.py\", line 1304, in __call__\n",
      "    return_value = get_return_value(\n",
      "  File \"/home/user/.local/lib/python3.8/site-packages/pyspark/sql/utils.py\", line 111, in deco\n",
      "    return f(*a, **kw)\n",
      "  File \"/home/user/.local/lib/python3.8/site-packages/py4j/protocol.py\", line 334, in get_return_value\n",
      "    raise Py4JError(\n",
      "py4j.protocol.Py4JError: An error occurred while calling o23.table\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 1934, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'Py4JError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user/.local/lib/python3.8/site-packages/py4j/java_gateway.py\", line 977, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user/.local/lib/python3.8/site-packages/py4j/java_gateway.py\", line 1115, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:40965)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3251, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_24253/2671758561.py\", line 1, in <module>\n",
      "    orders_stream_df = spark.table(\"orders_stream\").where(col('store_id') == 1)\n",
      "  File \"/home/user/.local/lib/python3.8/site-packages/pyspark/sql/session.py\", line 741, in table\n",
      "    return DataFrame(self._jsparkSession.table(tableName), self._wrapped)\n",
      "  File \"/home/user/.local/lib/python3.8/site-packages/py4j/java_gateway.py\", line 1304, in __call__\n",
      "    return_value = get_return_value(\n",
      "  File \"/home/user/.local/lib/python3.8/site-packages/pyspark/sql/utils.py\", line 111, in deco\n",
      "    return f(*a, **kw)\n",
      "  File \"/home/user/.local/lib/python3.8/site-packages/py4j/protocol.py\", line 334, in get_return_value\n",
      "    raise Py4JError(\n",
      "py4j.protocol.Py4JError: An error occurred while calling o23.table\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 1934, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'Py4JError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user/.local/lib/python3.8/site-packages/py4j/java_gateway.py\", line 977, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user/.local/lib/python3.8/site-packages/py4j/java_gateway.py\", line 1115, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:40965)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3251, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_24253/2671758561.py\", line 1, in <module>\n",
      "    orders_stream_df = spark.table(\"orders_stream\").where(col('store_id') == 1)\n",
      "  File \"/home/user/.local/lib/python3.8/site-packages/pyspark/sql/session.py\", line 741, in table\n",
      "    return DataFrame(self._jsparkSession.table(tableName), self._wrapped)\n",
      "  File \"/home/user/.local/lib/python3.8/site-packages/py4j/java_gateway.py\", line 1304, in __call__\n",
      "    return_value = get_return_value(\n",
      "  File \"/home/user/.local/lib/python3.8/site-packages/pyspark/sql/utils.py\", line 111, in deco\n",
      "    return f(*a, **kw)\n",
      "  File \"/home/user/.local/lib/python3.8/site-packages/py4j/protocol.py\", line 334, in get_return_value\n",
      "    raise Py4JError(\n",
      "py4j.protocol.Py4JError: An error occurred while calling o23.table\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 1934, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'Py4JError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user/.local/lib/python3.8/site-packages/py4j/java_gateway.py\", line 977, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user/.local/lib/python3.8/site-packages/py4j/java_gateway.py\", line 1115, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:40965)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3251, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_24253/2671758561.py\", line 1, in <module>\n",
      "    orders_stream_df = spark.table(\"orders_stream\").where(col('store_id') == 1)\n",
      "  File \"/home/user/.local/lib/python3.8/site-packages/pyspark/sql/session.py\", line 741, in table\n",
      "    return DataFrame(self._jsparkSession.table(tableName), self._wrapped)\n",
      "  File \"/home/user/.local/lib/python3.8/site-packages/py4j/java_gateway.py\", line 1304, in __call__\n",
      "    return_value = get_return_value(\n",
      "  File \"/home/user/.local/lib/python3.8/site-packages/pyspark/sql/utils.py\", line 111, in deco\n",
      "    return f(*a, **kw)\n",
      "  File \"/home/user/.local/lib/python3.8/site-packages/py4j/protocol.py\", line 334, in get_return_value\n",
      "    raise Py4JError(\n",
      "py4j.protocol.Py4JError: An error occurred while calling o23.table\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 1934, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'Py4JError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user/.local/lib/python3.8/site-packages/py4j/java_gateway.py\", line 977, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user/.local/lib/python3.8/site-packages/py4j/java_gateway.py\", line 1115, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n"
     ]
    },
    {
     "ename": "Py4JError",
     "evalue": "An error occurred while calling o23.table",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [9]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m orders_stream_df \u001b[38;5;241m=\u001b[39m \u001b[43mspark\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtable\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43morders_stream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mwhere(col(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstore_id\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pyspark/sql/session.py:741\u001b[0m, in \u001b[0;36mSparkSession.table\u001b[0;34m(self, tableName)\u001b[0m\n\u001b[1;32m    725\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtable\u001b[39m(\u001b[38;5;28mself\u001b[39m, tableName):\n\u001b[1;32m    726\u001b[0m     \u001b[38;5;124;03m\"\"\"Returns the specified table as a :class:`DataFrame`.\u001b[39;00m\n\u001b[1;32m    727\u001b[0m \n\u001b[1;32m    728\u001b[0m \u001b[38;5;124;03m    .. versionadded:: 2.0.0\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    739\u001b[0m \u001b[38;5;124;03m    True\u001b[39;00m\n\u001b[1;32m    740\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 741\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m DataFrame(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jsparkSession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtableName\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wrapped)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/py4j/java_gateway.py:1304\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1298\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1299\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1300\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1301\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1303\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1304\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1305\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1307\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1308\u001b[0m     temp_arg\u001b[38;5;241m.\u001b[39m_detach()\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pyspark/sql/utils.py:111\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdeco\u001b[39m(\u001b[38;5;241m*\u001b[39ma, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw):\n\u001b[1;32m    110\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 111\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m py4j\u001b[38;5;241m.\u001b[39mprotocol\u001b[38;5;241m.\u001b[39mPy4JJavaError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    113\u001b[0m         converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/py4j/protocol.py:334\u001b[0m, in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    330\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\n\u001b[1;32m    331\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m. Trace:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{3}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m    332\u001b[0m                 \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name, value))\n\u001b[1;32m    333\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 334\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\n\u001b[1;32m    335\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m    336\u001b[0m             \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name))\n\u001b[1;32m    337\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    338\u001b[0m     \u001b[38;5;28mtype\u001b[39m \u001b[38;5;241m=\u001b[39m answer[\u001b[38;5;241m1\u001b[39m]\n",
      "\u001b[0;31mPy4JError\u001b[0m: An error occurred while calling o23.table"
     ]
    }
   ],
   "source": [
    "orders_stream_df = spark.table(\"orders_stream\").where(col('store_id') == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5d10e263",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'orders_stream_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [10]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43morders_stream_df\u001b[49m\u001b[38;5;241m.\u001b[39mhead()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'orders_stream_df' is not defined"
     ]
    }
   ],
   "source": [
    "orders_stream_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5a7b790d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:40965)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user/.local/lib/python3.8/site-packages/py4j/java_gateway.py\", line 977, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user/.local/lib/python3.8/site-packages/py4j/java_gateway.py\", line 1115, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n"
     ]
    },
    {
     "ename": "Py4JNetworkError",
     "evalue": "An error occurred while trying to connect to the Java server (127.0.0.1:40965)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/py4j/java_gateway.py:977\u001b[0m, in \u001b[0;36mGatewayClient._get_connection\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    976\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 977\u001b[0m     connection \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdeque\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    978\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m:\n",
      "\u001b[0;31mIndexError\u001b[0m: pop from an empty deque",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mConnectionRefusedError\u001b[0m                    Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/py4j/java_gateway.py:1115\u001b[0m, in \u001b[0;36mGatewayConnection.start\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1114\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1115\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msocket\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maddress\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mport\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1116\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msocket\u001b[38;5;241m.\u001b[39mmakefile(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mConnectionRefusedError\u001b[0m: [Errno 111] Connection refused",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mPy4JNetworkError\u001b[0m                          Traceback (most recent call last)",
      "Input \u001b[0;32mIn [11]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mspark\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msql\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\"\"\u001b[39;49m\u001b[38;5;124;43m SELECT COUNT(*) FROM orders_stream WHERE store_id = 1\u001b[39;49m\u001b[38;5;124;43m\"\"\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mshow()\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pyspark/sql/session.py:723\u001b[0m, in \u001b[0;36mSparkSession.sql\u001b[0;34m(self, sqlQuery)\u001b[0m\n\u001b[1;32m    707\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msql\u001b[39m(\u001b[38;5;28mself\u001b[39m, sqlQuery):\n\u001b[1;32m    708\u001b[0m     \u001b[38;5;124;03m\"\"\"Returns a :class:`DataFrame` representing the result of the given query.\u001b[39;00m\n\u001b[1;32m    709\u001b[0m \n\u001b[1;32m    710\u001b[0m \u001b[38;5;124;03m    .. versionadded:: 2.0.0\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    721\u001b[0m \u001b[38;5;124;03m    [Row(f1=1, f2='row1'), Row(f1=2, f2='row2'), Row(f1=3, f2='row3')]\u001b[39;00m\n\u001b[1;32m    722\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 723\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m DataFrame(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jsparkSession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msql\u001b[49m\u001b[43m(\u001b[49m\u001b[43msqlQuery\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wrapped)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/py4j/java_gateway.py:1303\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1296\u001b[0m args_command, temp_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_args(\u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m   1298\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1299\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1300\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1301\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[0;32m-> 1303\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_command\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1304\u001b[0m return_value \u001b[38;5;241m=\u001b[39m get_return_value(\n\u001b[1;32m   1305\u001b[0m     answer, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_id, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname)\n\u001b[1;32m   1307\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/py4j/java_gateway.py:1031\u001b[0m, in \u001b[0;36mGatewayClient.send_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m   1010\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msend_command\u001b[39m(\u001b[38;5;28mself\u001b[39m, command, retry\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, binary\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m   1011\u001b[0m     \u001b[38;5;124;03m\"\"\"Sends a command to the JVM. This method is not intended to be\u001b[39;00m\n\u001b[1;32m   1012\u001b[0m \u001b[38;5;124;03m       called directly by Py4J users. It is usually called by\u001b[39;00m\n\u001b[1;32m   1013\u001b[0m \u001b[38;5;124;03m       :class:`JavaMember` instances.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1029\u001b[0m \u001b[38;5;124;03m     if `binary` is `True`.\u001b[39;00m\n\u001b[1;32m   1030\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1031\u001b[0m     connection \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_connection\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1032\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1033\u001b[0m         response \u001b[38;5;241m=\u001b[39m connection\u001b[38;5;241m.\u001b[39msend_command(command)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/py4j/java_gateway.py:979\u001b[0m, in \u001b[0;36mGatewayClient._get_connection\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    977\u001b[0m     connection \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdeque\u001b[38;5;241m.\u001b[39mpop()\n\u001b[1;32m    978\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m:\n\u001b[0;32m--> 979\u001b[0m     connection \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_connection\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    980\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m connection\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/py4j/java_gateway.py:985\u001b[0m, in \u001b[0;36mGatewayClient._create_connection\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    982\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_create_connection\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    983\u001b[0m     connection \u001b[38;5;241m=\u001b[39m GatewayConnection(\n\u001b[1;32m    984\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_parameters, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_property)\n\u001b[0;32m--> 985\u001b[0m     \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    986\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m connection\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/py4j/java_gateway.py:1127\u001b[0m, in \u001b[0;36mGatewayConnection.start\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1124\u001b[0m msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while trying to connect to the Java \u001b[39m\u001b[38;5;124m\"\u001b[39m\\\n\u001b[1;32m   1125\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mserver (\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maddress, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mport)\n\u001b[1;32m   1126\u001b[0m logger\u001b[38;5;241m.\u001b[39mexception(msg)\n\u001b[0;32m-> 1127\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m Py4JNetworkError(msg, e)\n",
      "\u001b[0;31mPy4JNetworkError\u001b[0m: An error occurred while trying to connect to the Java server (127.0.0.1:40965)"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\" SELECT COUNT(*) FROM orders_stream WHERE store_id = 1\"\"\").show()\n",
    "# %sql\n",
    "# select count(*) from orders_stream where store_id = 1    # DataBricks selecting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58fbcd64",
   "metadata": {},
   "outputs": [],
   "source": [
    "orders_stream_df = orders_stream_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f14c28c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "client_df = spark.read\\\n",
    "    .option(\"header\", True)\\\n",
    "    .option(\"inferSchema\", True)\\\n",
    "    .parquet(\"/datalake/silver/dshop/clients/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51024d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "client_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335f30ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
