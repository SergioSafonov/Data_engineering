{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9dcbb8eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "import psycopg2\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "from hdfs import InsecureClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab3f964b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "21/08/05 16:19:26 WARN util.Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession\\\n",
    "    .builder\\\n",
    "    .config('spark.driver.extraClassPath'\n",
    "            , '/home/user/shared_folder/postgresql-42.2.23.jar')\\\n",
    "    .master('local')\\\n",
    "    .appName(\"homework_6\")\\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b751b1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Pagila tables to Bronze HDFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8db88ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pg_creds = {\n",
    "      'host': '192.168.88.138'\n",
    "    , 'port': '5432'\n",
    "    , 'database': 'pagila'\n",
    "    , 'user': 'pguser'\n",
    "    , 'password': 'secret'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7298d6ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "tables_to_load = (  \n",
    "     'actor'\n",
    "    ,'category'\n",
    "    ,'film'\n",
    "    ,'film_actor'\n",
    "    ,'film_category'\n",
    "    ,'customer'\n",
    "    ,'address'\n",
    "    ,'city'\n",
    "    ,'inventory'\n",
    "    ,'rental'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f185e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "hdfs_url = 'http://127.0.0.1:50070/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3bba3475",
   "metadata": {},
   "outputs": [],
   "source": [
    "client_hdfs = InsecureClient(hdfs_url, user='user')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b80be2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_date = datetime.now().strftime(\"%Y-%m-%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "029eb048",
   "metadata": {},
   "outputs": [],
   "source": [
    "for table_name in tables_to_load:\n",
    "    \n",
    "    bronze_dir = os.path.join('/', 'bronze', 'pagila', table_name, current_date)\n",
    "    \n",
    "    with psycopg2.connect(**pg_creds) as pg_connection:\n",
    "        cursor = pg_connection.cursor()\n",
    "        \n",
    "        with client_hdfs.write(os.path.join(bronze_dir, table_name + '.csv')) as csv_file:\n",
    "            \n",
    "            client_hdfs.delete(os.path.join(bronze_dir, table_name + '.csv') , recursive=False)\n",
    "            cursor.copy_expert(f\"COPY {table_name} TO STDOUT WITH HEADER CSV\", csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1895b00e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read used csv files to DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5448ac0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "actor_df = spark.read.load(\n",
    "    os.path.join('/', 'bronze', 'pagila', 'actor', current_date, 'actor.csv')\n",
    "    , header=\"true\"\n",
    "    , inferSchema=\"true\"\n",
    "    , format=\"csv\"\n",
    ")\n",
    "category_df = spark.read.load(\n",
    "    os.path.join('/', 'bronze', 'pagila', 'category', current_date, 'category.csv')\n",
    "    , header=\"true\"\n",
    "    , inferSchema=\"true\"\n",
    "    , format=\"csv\"\n",
    ")\n",
    "film_df = spark.read.load(\n",
    "    os.path.join('/', 'bronze', 'pagila', 'film', current_date, 'film.csv')\n",
    "    , header=\"true\"\n",
    "    , inferSchema=\"true\"\n",
    "    , format=\"csv\"\n",
    ")\n",
    "film_actor_df = spark.read.load(\n",
    "    os.path.join('/', 'bronze', 'pagila', 'film_actor', current_date, 'film_actor.csv')\n",
    "    , header=\"true\"\n",
    "    , inferSchema=\"true\"\n",
    "    , format=\"csv\"\n",
    ")\n",
    "film_category_df = spark.read.load(\n",
    "    os.path.join('/', 'bronze', 'pagila', 'film_category', current_date, 'film_category.csv')\n",
    "    , header=\"true\"\n",
    "    , inferSchema=\"true\"\n",
    "    , format=\"csv\"\n",
    ")\n",
    "customer_df = spark.read.load(\n",
    "    os.path.join('/', 'bronze', 'pagila', 'customer', current_date, 'customer.csv')\n",
    "    , header=\"true\"\n",
    "    , inferSchema=\"true\"\n",
    "    , format=\"csv\"\n",
    ")\n",
    "address_df = spark.read.load(\n",
    "    os.path.join('/', 'bronze', 'pagila', 'address', current_date, 'address.csv')\n",
    "    , header=\"true\"\n",
    "    , inferSchema=\"true\"\n",
    "    , format=\"csv\"\n",
    ")\n",
    "city_df = spark.read.load(\n",
    "    os.path.join('/', 'bronze', 'pagila', 'city', current_date, 'city.csv')\n",
    "    , header=\"true\"\n",
    "    , inferSchema=\"true\"\n",
    "    , format=\"csv\"\n",
    ")\n",
    "inventory_df = spark.read.load(\n",
    "    os.path.join('/', 'bronze', 'pagila', 'inventory', current_date, 'inventory.csv')\n",
    "    , header=\"true\"\n",
    "    , inferSchema=\"true\"\n",
    "    , format=\"csv\"\n",
    ")\n",
    "rental_df = spark.read.load(\n",
    "    os.path.join('/', 'bronze', 'pagila', 'rental', current_date, 'rental.csv')\n",
    "    , header=\"true\"\n",
    "    , inferSchema=\"true\"\n",
    "    , format=\"csv\"\n",
    ")\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3ae6d09e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# вывести количество фильмов в каждой категории, отсортировать по убыванию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0b740c2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----+\n",
      "|category_name|count|\n",
      "+-------------+-----+\n",
      "|       Sports|   74|\n",
      "|      Foreign|   73|\n",
      "|       Family|   69|\n",
      "|  Documentary|   68|\n",
      "|    Animation|   66|\n",
      "|       Action|   64|\n",
      "|          New|   63|\n",
      "|        Drama|   62|\n",
      "|       Sci-Fi|   61|\n",
      "|        Games|   61|\n",
      "|     Children|   60|\n",
      "|       Comedy|   58|\n",
      "|       Travel|   57|\n",
      "|     Classics|   57|\n",
      "|       Horror|   56|\n",
      "|        Music|   51|\n",
      "+-------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result_1 = film_category_df.join(category_df\n",
    "        , film_category_df.category_id == category_df.category_id\n",
    "        , 'inner')\\\n",
    "    .select(category_df.name.alias('category_name'))\n",
    "\n",
    "result_1.groupBy(result_1.category_name)\\\n",
    "    .count().orderBy(F.desc(\"count\")).show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
